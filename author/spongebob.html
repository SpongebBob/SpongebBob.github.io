<!DOCTYPE html>
<html lang="zh">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>Bobbbb - Articles by SpongeBob</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="/theme/css/poole.css" />
		<link rel="stylesheet" href="/theme/css/hyde.css" />
		<link rel="stylesheet" href="/theme/css/syntax.css" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

		<!-- RSS -->
		<link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="/images/avatar.png">
					Bobbbb
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead">I'm SpongeBob, a student from BUAA. Working in ACT lab. </p>
			<p></p>
		</div>
		<nav class="sidebar-nav">
			<a class="sidebar-nav-item" href="http://weibo.com/u/2893779987">
				<i class="fa fa-weibo"></i>
			</a>
			<a class="sidebar-nav-item" href="https://github.com/spongeBbob">
				<i class="fa fa-github"></i>
			</a>
			
		</nav>
	</div>
</div>		<div class="content container">
	<div class="posts">
			<div class="post">
				<h1 class="post-title" href="/bpshen-jing-wang-luo.html#bpshen-jing-wang-luo">
					<a href="/bpshen-jing-wang-luo.html#bpshen-jing-wang-luo">BP神经网络</a>
				</h1>
				<span class="post-date">一 11 七月 2016</span>
				<p>
					<p>首先我们从感知器和单个神经元的关系来讲起
单个神经元</p>
<hr />
<p>前几天上课的时候老师讲了一个感知器的例子。当时理解不深刻，只知道这东西可以通过学习来分类一个线性可分的东西。然后还讲了感知器中的一种奇怪的并不是梯度下降的方法来训练，然而梯度下降十分好理解和好用。线性分类器确实是一类比较简单的东西。</p>
<p>单个神经元就是一个感知器，加上一个<code>sigmod</code>函数即可。一个神经元的训练也可以归结到一个线性回归的问题。一个比较直观的例子来自某个slide</p>
<div class="highlight"><pre><span></span>Each day you get lunch at the cafeteria. Your diet consists of fish, chips, and ketchup. You get several portions of each. The cashier only tells you the total price of the meal. After several days ...</pre></div>
				</p>
				<a class="read-more" href="bpshen-jing-wang-luo.html">Continue reading »</a>
			</div>
			<div class="post">
				<h1 class="post-title" href="/glove-sumarry.html#glove-sumarry">
					<a href="/glove-sumarry.html#glove-sumarry">GloVe Sumarry</a>
				</h1>
				<span class="post-date">一 11 七月 2016</span>
				<p>
					<p>在前边的文章我们已经讲了词向量的两种表达方式，一种是<code>"one-hot"</code>，另外一种是<code>"distributed word representation"</code>。针对"one-hot"的种种弊端：只能表达词本身是否出现，而无法表达词与词之间的关系。而自然语言处理中的一个基本的指导思想就是，一个词的含义，跟它的上下文有关系。比如我们可以想像一下，“坚硬的”和“冰块”共同出现的概率一定要比“坚硬的”和“河流”共同出现的概率大。他们的上下文隐含一定的语义信息。</p>
<p>针使用矩阵对表示词向量的方法，主要两种方法。一种是<code>“word-doc”</code>另一种是<code>"word-word"</code>，用两种统计信息来表达一个贡献矩阵。而我们今天要讨论的<code>GloVe</code>就是采用<code>“word-word”</code>的共现矩阵。</p>
<p>但是，直接直接从共现矩阵中提取的词向量，有这样一个问题，维度非常高，和预料库的文档数，以及词汇量成正相关。并且还有另外一个问题，这个矩阵可能非常稀疏。所以会浪费很多的计算和存储资源。如何解决呢？前面已经提到了。</p>
<p>下面就是<code>"distributed ...</code></p>
				</p>
				<a class="read-more" href="glove-sumarry.html">Continue reading »</a>
			</div>
			<div class="post">
				<h1 class="post-title" href="/word-emdedding-summary.html#word-emdedding-summary">
					<a href="/word-emdedding-summary.html#word-emdedding-summary">word emdedding summary</a>
				</h1>
				<span class="post-date">日 10 七月 2016</span>
				<p>
					<p>A week ago I came to the ACT lab. My mentor gave me some papers to read. One in these papers ,<a href="http://nlp.stanford.edu/pubs/glove.pdf">GloVe: Global Vectors for Word Representation.</a></p>
<p>This paper introduces a method to  learn vector space representations of words. The model efficiently leverages statistical information by training only on the ...</p>
				</p>
				<a class="read-more" href="word-emdedding-summary.html">Continue reading »</a>
			</div>
	</div>
	<div class="pagination">
		<span class="pagination-item older">Older</span>
		<span class="pagination-item newer">Newer</span>

	</div>
		</div>
	</body>
</html>